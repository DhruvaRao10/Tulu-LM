{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12378065,"sourceType":"datasetVersion","datasetId":7804866}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import PreTrainedTokenizerFast \n\ntokenizer = PreTrainedTokenizerFast.from_pretrained(\"charanhu/kannada-tokenizer\")\n\ntext = train_data['tgt']\nsrc_text = train_data['src']\n\nprint(text[2])\nprint(src_text[2])","metadata":{"trusted":true,"execution":{"execution_failed":"2025-06-28T15:58:19.157Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for i, s_txt in enumerate(text):\n    encoding = tokenizer.encode(s_txt) \n    tokens = tokenizer.convert_ids_to_tokens(encoding) \n    decoded_text = tokenizer.decode(encoding) \n\n    # print(f\"original text : {s_txt}\") \n    # print(f\"encoded text: {encoding}\")\n    # print(f\"tokens: {tokens}\") \n    # print(f\"decoded_text: {decoded_text}\") ","metadata":{"trusted":true,"execution":{"execution_failed":"2025-06-28T15:58:19.157Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoModel, AutoTokenizer\nimport itertools\nimport torch\n\n# load model\nmodel = AutoModel.from_pretrained(\"aneuraz/awesome-align-with-co\")\ntokenizer = AutoTokenizer.from_pretrained(\"aneuraz/awesome-align-with-co\")\n\n# model parameters\nalign_layer = 8\nthreshold = 1e-3\n\n# define inputs\nsrc = 'the universe is vast and who knows how many species are within it.'\ntgt = 'ವಿಶ್ವವು ವಿಶಾಲವಾಗಿದೆ ಮತ್ತು ಅದರೊಳಗೆ ಎಷ್ಟು ಜಾತಿಗಳಿವೆ ಎಂದು ಯಾರಿಗೆ ತಿಳಿದಿದೆ.'\n\n# pre-processing\nsent_src, sent_tgt = src.strip().split(), tgt.strip().split()\n\nprint(\"=\"*50)\nprint(\"original words:\")\nprint(\"=\"*50)\nprint(\"Source words:\", sent_src)\nprint(\"Target words:\", sent_tgt)\nprint()\n\ntoken_src, token_tgt = [tokenizer.tokenize(word) for word in sent_src], [tokenizer.tokenize(word) for word in sent_tgt]\n\nprint(\"=\"*50)\nprint(\"tokenization (Word -> Subwords):\")\nprint(\"=\"*50)\nprint(\"src tokenization:\")\nfor i, (word, tokens) in enumerate(zip(sent_src, token_src)):\n    print(f\"Word {i}: '{word}' -> {tokens}\")\n\nprint(\"\\tgt tokenization:\")\nfor i, (word, tokens) in enumerate(zip(sent_tgt, token_tgt)):\n    print(f\"Word {i}: '{word}' -> {tokens}\")\nprint()\n\nflat_tokens_src = list(itertools.chain(*token_src))\nflat_tokens_tgt = list(itertools.chain(*token_tgt))\n\nprint(\"=\"*50)\nprint(\"=\"*50)\nprint(\"src subwords :\")\nfor i, token in enumerate(flat_tokens_src):\n    print(f\"Subword {i}: '{token}'\")\n\nprint(\"\\n tgt subwords:\")\nfor i, token in enumerate(flat_tokens_tgt):\n    print(f\"Subword {i}: '{token}'\")\nprint()\n\n# Convert to IDs\nwid_src, wid_tgt = [tokenizer.convert_tokens_to_ids(x) for x in token_src], [tokenizer.convert_tokens_to_ids(x) for x in token_tgt]\n\nprint(\"=\"*50)\nprint(\"token ids (Word level):\")\nprint(\"=\"*50)\nprint(\"src token ids:\")\nfor i, (word, tokens, ids) in enumerate(zip(sent_src, token_src, wid_src)):\n    print(f\"Word {i}: '{word}' -> tokens: {tokens} -> ids: {ids}\")\n\nprint(\"\\tgt token ids:\")\nfor i, (word, tokens, ids) in enumerate(zip(sent_tgt, token_tgt, wid_tgt)):\n    print(f\"Word {i}: '{word}' -> tokens: {tokens} -> ids: {ids}\")\nprint()\n\nids_src = tokenizer.prepare_for_model(list(itertools.chain(*wid_src)), return_tensors='pt', model_max_length=tokenizer.model_max_length, truncation=True)['input_ids']\nids_tgt = tokenizer.prepare_for_model(list(itertools.chain(*wid_tgt)), return_tensors='pt', truncation=True, model_max_length=tokenizer.model_max_length)['input_ids']\n\nprint(\"=\"*50)\nprint(\"final model input (with special tokens):\")\nprint(\"=\"*50)\nprint(\"SOURCE INPUT IDs:\", ids_src.squeeze().tolist())\nprint(\"SOURCE TOKENS:\", tokenizer.convert_ids_to_tokens(ids_src.squeeze().tolist()))\n\nprint(\"\\target input ids:\", ids_tgt.squeeze().tolist())\nprint(\"tgt tokens:\", tokenizer.convert_ids_to_tokens(ids_tgt.squeeze().tolist()))\nprint()\n\nsub2word_map_src = []\nsub2word_map_tgt = []\n\nprint(\"=\"*50)\nprint(\"subword to word mapping\")\nprint(\"=\"*50)\nprint(\"src mapping \")\nsubword_idx_src = 0\nfor word_idx, word_tokens in enumerate(token_src):\n    print(f\"Word {word_idx} ('{sent_src[word_idx]}'):\")\n    for token in word_tokens:\n        print(f\"  Subword {subword_idx_src}: '{token}' -> maps to word {word_idx}\")\n        sub2word_map_src.append(word_idx)\n        subword_idx_src += 1\n\nprint(f\"\\nSource sub2word_map: {sub2word_map_src}\")\n\nsubword_idx_tgt = 0\nfor word_idx, word_tokens in enumerate(token_tgt):\n    print(f\"Word {word_idx} ('{sent_tgt[word_idx]}'):\")\n    for token in word_tokens:\n        print(f\"  Subword {subword_idx_tgt}: '{token}' -> maps to word {word_idx}\")\n        sub2word_map_tgt.append(word_idx)\n        subword_idx_tgt += 1\n\n\n# alignment\nmodel.eval()\nwith torch.no_grad():\n    out_src = model(ids_src.unsqueeze(0), output_hidden_states=True)[2][align_layer][0, 1:-1]\n    out_tgt = model(ids_tgt.unsqueeze(0), output_hidden_states=True)[2][align_layer][0, 1:-1]\n    dot_prod = torch.matmul(out_src, out_tgt.transpose(-1, -2))\n    softmax_srctgt = torch.nn.Softmax(dim=-1)(dot_prod)\n    softmax_tgtsrc = torch.nn.Softmax(dim=-2)(dot_prod)\n    softmax_inter = (softmax_srctgt > threshold)*(softmax_tgtsrc > threshold)\n\nalign_subwords = torch.nonzero(softmax_inter, as_tuple=False)\nalign_words = set()\n\nprint(\"=\"*50)\nprint(\"=\"*50)\nfor i, j in align_subwords:\n    src_subword = flat_tokens_src[i.item()]\n    tgt_subword = flat_tokens_tgt[j.item()]\n    src_word_idx = sub2word_map_src[i.item()]\n    tgt_word_idx = sub2word_map_tgt[j.item()]\n    src_word = sent_src[src_word_idx]\n    tgt_word = sent_tgt[tgt_word_idx]\n    \n    print(f\"Subword {i.item()} '{src_subword}' (from word {src_word_idx} '{src_word}') <-> \"\n          f\"Subword {j.item()} '{tgt_subword}' (from word {tgt_word_idx} '{tgt_word}')\")\n    \n    align_words.add((src_word_idx, tgt_word_idx))\n\nprint(f\"\\nWORD-LEVEL ALIGNMENTS:\")\nfor src_idx, tgt_idx in sorted(align_words):\n    print(f\"Word {src_idx} '{sent_src[src_idx]}' <-> Word {tgt_idx} '{sent_tgt[tgt_idx]}'\")\n\nprint(f\"\\nFinal alignment set: {align_words}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T14:22:41.438041Z","iopub.execute_input":"2025-07-01T14:22:41.438217Z","iopub.status.idle":"2025-07-01T14:23:19.340634Z","shell.execute_reply.started":"2025-07-01T14:22:41.438202Z","shell.execute_reply":"2025-07-01T14:23:19.339546Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c47804db06946a4ae4c450b2d24c5e7"}},"metadata":{}},{"name":"stderr","text":"2025-07-01 14:22:58.823366: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1751379779.014786      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1751379779.074126      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.09G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c08f64d60a5947299ea1ea33a9696dad"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertModel were not initialized from the model checkpoint at aneuraz/awesome-align-with-co and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.09G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1465dde0c366432d8d764d9f95539b73"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/40.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6b0bfc9f66c430b8c478fbe4b44e664"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fce35502593446f9a71a29fa8580fc8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"616c622563864225a9d59a3d4126ca78"}},"metadata":{}},{"name":"stderr","text":"You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"},{"name":"stdout","text":"==================================================\nORIGINAL WORDS:\n==================================================\nSource words: ['the', 'universe', 'is', 'vast', 'and', 'who', 'knows', 'how', 'many', 'species', 'are', 'within', 'it.']\nTarget words: ['ವಿಶ್ವವು', 'ವಿಶಾಲವಾಗಿದೆ', 'ಮತ್ತು', 'ಅದರೊಳಗೆ', 'ಎಷ್ಟು', 'ಜಾತಿಗಳಿವೆ', 'ಎಂದು', 'ಯಾರಿಗೆ', 'ತಿಳಿದಿದೆ.']\n\n==================================================\nTOKENIZATION (Word -> Subwords):\n==================================================\nSOURCE TOKENIZATION:\nWord 0: 'the' -> ['the']\nWord 1: 'universe' -> ['universe']\nWord 2: 'is' -> ['is']\nWord 3: 'vast' -> ['vast']\nWord 4: 'and' -> ['and']\nWord 5: 'who' -> ['who']\nWord 6: 'knows' -> ['knows']\nWord 7: 'how' -> ['how']\nWord 8: 'many' -> ['many']\nWord 9: 'species' -> ['species']\nWord 10: 'are' -> ['are']\nWord 11: 'within' -> ['within']\nWord 12: 'it.' -> ['it', '.']\n\nTARGET TOKENIZATION:\nWord 0: 'ವಿಶ್ವವು' -> ['ವ', '##ಿ', '##ಶ್', '##ವ', '##ವು']\nWord 1: 'ವಿಶಾಲವಾಗಿದೆ' -> ['ವ', '##ಿ', '##ಶ', '##ಾಲ', '##ವಾಗಿದೆ']\nWord 2: 'ಮತ್ತು' -> ['ಮತ್ತು']\nWord 3: 'ಅದರೊಳಗೆ' -> ['ಅದರ', '##ೊ', '##ಳ', '##ಗೆ']\nWord 4: 'ಎಷ್ಟು' -> ['ಎ', '##ಷ್ಟು']\nWord 5: 'ಜಾತಿಗಳಿವೆ' -> ['ಜ', '##ಾತ', '##ಿ', '##ಗಳ', '##ಿವೆ']\nWord 6: 'ಎಂದು' -> ['ಎಂದು']\nWord 7: 'ಯಾರಿಗೆ' -> ['ಯ', '##ಾರಿಗೆ']\nWord 8: 'ತಿಳಿದಿದೆ.' -> ['ತ', '##ಿ', '##ಳಿದ', '##ಿದೆ', '.']\n\n==================================================\nFLATTENED SUBWORD TOKENS WITH INDICES:\n==================================================\nSOURCE SUBWORDS:\nSubword 0: 'the'\nSubword 1: 'universe'\nSubword 2: 'is'\nSubword 3: 'vast'\nSubword 4: 'and'\nSubword 5: 'who'\nSubword 6: 'knows'\nSubword 7: 'how'\nSubword 8: 'many'\nSubword 9: 'species'\nSubword 10: 'are'\nSubword 11: 'within'\nSubword 12: 'it'\nSubword 13: '.'\n\nTARGET SUBWORDS:\nSubword 0: 'ವ'\nSubword 1: '##ಿ'\nSubword 2: '##ಶ್'\nSubword 3: '##ವ'\nSubword 4: '##ವು'\nSubword 5: 'ವ'\nSubword 6: '##ಿ'\nSubword 7: '##ಶ'\nSubword 8: '##ಾಲ'\nSubword 9: '##ವಾಗಿದೆ'\nSubword 10: 'ಮತ್ತು'\nSubword 11: 'ಅದರ'\nSubword 12: '##ೊ'\nSubword 13: '##ಳ'\nSubword 14: '##ಗೆ'\nSubword 15: 'ಎ'\nSubword 16: '##ಷ್ಟು'\nSubword 17: 'ಜ'\nSubword 18: '##ಾತ'\nSubword 19: '##ಿ'\nSubword 20: '##ಗಳ'\nSubword 21: '##ಿವೆ'\nSubword 22: 'ಎಂದು'\nSubword 23: 'ಯ'\nSubword 24: '##ಾರಿಗೆ'\nSubword 25: 'ತ'\nSubword 26: '##ಿ'\nSubword 27: '##ಳಿದ'\nSubword 28: '##ಿದೆ'\nSubword 29: '.'\n\n==================================================\nTOKEN IDs (Word level):\n==================================================\nSOURCE TOKEN IDs:\nWord 0: 'the' -> tokens: ['the'] -> ids: [10105]\nWord 1: 'universe' -> tokens: ['universe'] -> ids: [54607]\nWord 2: 'is' -> tokens: ['is'] -> ids: [10124]\nWord 3: 'vast' -> tokens: ['vast'] -> ids: [35472]\nWord 4: 'and' -> tokens: ['and'] -> ids: [10111]\nWord 5: 'who' -> tokens: ['who'] -> ids: [10479]\nWord 6: 'knows' -> tokens: ['knows'] -> ids: [75354]\nWord 7: 'how' -> tokens: ['how'] -> ids: [14796]\nWord 8: 'many' -> tokens: ['many'] -> ids: [11299]\nWord 9: 'species' -> tokens: ['species'] -> ids: [10542]\nWord 10: 'are' -> tokens: ['are'] -> ids: [10301]\nWord 11: 'within' -> tokens: ['within'] -> ids: [12381]\nWord 12: 'it.' -> tokens: ['it', '.'] -> ids: [10271, 119]\n\nTARGET TOKEN IDs:\nWord 0: 'ವಿಶ್ವವು' -> tokens: ['ವ', '##ಿ', '##ಶ್', '##ವ', '##ವು'] -> ids: [1291, 13232, 93866, 21136, 16015]\nWord 1: 'ವಿಶಾಲವಾಗಿದೆ' -> tokens: ['ವ', '##ಿ', '##ಶ', '##ಾಲ', '##ವಾಗಿದೆ'] -> ids: [1291, 13232, 37206, 80305, 45880]\nWord 2: 'ಮತ್ತು' -> tokens: ['ಮತ್ತು'] -> ids: [11625]\nWord 3: 'ಅದರೊಳಗೆ' -> tokens: ['ಅದರ', '##ೊ', '##ಳ', '##ಗೆ'] -> ids: [41726, 57508, 31903, 15206]\nWord 4: 'ಎಷ್ಟು' -> tokens: ['ಎ', '##ಷ್ಟು'] -> ids: [1257, 34012]\nWord 5: 'ಜಾತಿಗಳಿವೆ' -> tokens: ['ಜ', '##ಾತ', '##ಿ', '##ಗಳ', '##ಿವೆ'] -> ids: [1269, 97051, 13232, 14252, 61445]\nWord 6: 'ಎಂದು' -> tokens: ['ಎಂದು'] -> ids: [18941]\nWord 7: 'ಯಾರಿಗೆ' -> tokens: ['ಯ', '##ಾರಿಗೆ'] -> ids: [1287, 92162]\nWord 8: 'ತಿಳಿದಿದೆ.' -> tokens: ['ತ', '##ಿ', '##ಳಿದ', '##ಿದೆ', '.'] -> ids: [1277, 13232, 93271, 67070, 119]\n\n==================================================\nFINAL MODEL INPUT (with special tokens):\n==================================================\nSOURCE INPUT IDs: [101, 10105, 54607, 10124, 35472, 10111, 10479, 75354, 14796, 11299, 10542, 10301, 12381, 10271, 119, 102]\nSOURCE TOKENS: ['[CLS]', 'the', 'universe', 'is', 'vast', 'and', 'who', 'knows', 'how', 'many', 'species', 'are', 'within', 'it', '.', '[SEP]']\n\nTARGET INPUT IDs: [101, 1291, 13232, 93866, 21136, 16015, 1291, 13232, 37206, 80305, 45880, 11625, 41726, 57508, 31903, 15206, 1257, 34012, 1269, 97051, 13232, 14252, 61445, 18941, 1287, 92162, 1277, 13232, 93271, 67070, 119, 102]\nTARGET TOKENS: ['[CLS]', 'ವ', '##ಿ', '##ಶ್', '##ವ', '##ವು', 'ವ', '##ಿ', '##ಶ', '##ಾಲ', '##ವಾಗಿದೆ', 'ಮತ್ತು', 'ಅದರ', '##ೊ', '##ಳ', '##ಗೆ', 'ಎ', '##ಷ್ಟು', 'ಜ', '##ಾತ', '##ಿ', '##ಗಳ', '##ಿವೆ', 'ಎಂದು', 'ಯ', '##ಾರಿಗೆ', 'ತ', '##ಿ', '##ಳಿದ', '##ಿದೆ', '.', '[SEP]']\n\n==================================================\nSUBWORD TO WORD MAPPING:\n==================================================\nSOURCE MAPPING:\nWord 0 ('the'):\n  Subword 0: 'the' -> maps to word 0\nWord 1 ('universe'):\n  Subword 1: 'universe' -> maps to word 1\nWord 2 ('is'):\n  Subword 2: 'is' -> maps to word 2\nWord 3 ('vast'):\n  Subword 3: 'vast' -> maps to word 3\nWord 4 ('and'):\n  Subword 4: 'and' -> maps to word 4\nWord 5 ('who'):\n  Subword 5: 'who' -> maps to word 5\nWord 6 ('knows'):\n  Subword 6: 'knows' -> maps to word 6\nWord 7 ('how'):\n  Subword 7: 'how' -> maps to word 7\nWord 8 ('many'):\n  Subword 8: 'many' -> maps to word 8\nWord 9 ('species'):\n  Subword 9: 'species' -> maps to word 9\nWord 10 ('are'):\n  Subword 10: 'are' -> maps to word 10\nWord 11 ('within'):\n  Subword 11: 'within' -> maps to word 11\nWord 12 ('it.'):\n  Subword 12: 'it' -> maps to word 12\n  Subword 13: '.' -> maps to word 12\n\nSource sub2word_map: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12]\n\nTARGET MAPPING:\nWord 0 ('ವಿಶ್ವವು'):\n  Subword 0: 'ವ' -> maps to word 0\n  Subword 1: '##ಿ' -> maps to word 0\n  Subword 2: '##ಶ್' -> maps to word 0\n  Subword 3: '##ವ' -> maps to word 0\n  Subword 4: '##ವು' -> maps to word 0\nWord 1 ('ವಿಶಾಲವಾಗಿದೆ'):\n  Subword 5: 'ವ' -> maps to word 1\n  Subword 6: '##ಿ' -> maps to word 1\n  Subword 7: '##ಶ' -> maps to word 1\n  Subword 8: '##ಾಲ' -> maps to word 1\n  Subword 9: '##ವಾಗಿದೆ' -> maps to word 1\nWord 2 ('ಮತ್ತು'):\n  Subword 10: 'ಮತ್ತು' -> maps to word 2\nWord 3 ('ಅದರೊಳಗೆ'):\n  Subword 11: 'ಅದರ' -> maps to word 3\n  Subword 12: '##ೊ' -> maps to word 3\n  Subword 13: '##ಳ' -> maps to word 3\n  Subword 14: '##ಗೆ' -> maps to word 3\nWord 4 ('ಎಷ್ಟು'):\n  Subword 15: 'ಎ' -> maps to word 4\n  Subword 16: '##ಷ್ಟು' -> maps to word 4\nWord 5 ('ಜಾತಿಗಳಿವೆ'):\n  Subword 17: 'ಜ' -> maps to word 5\n  Subword 18: '##ಾತ' -> maps to word 5\n  Subword 19: '##ಿ' -> maps to word 5\n  Subword 20: '##ಗಳ' -> maps to word 5\n  Subword 21: '##ಿವೆ' -> maps to word 5\nWord 6 ('ಎಂದು'):\n  Subword 22: 'ಎಂದು' -> maps to word 6\nWord 7 ('ಯಾರಿಗೆ'):\n  Subword 23: 'ಯ' -> maps to word 7\n  Subword 24: '##ಾರಿಗೆ' -> maps to word 7\nWord 8 ('ತಿಳಿದಿದೆ.'):\n  Subword 25: 'ತ' -> maps to word 8\n  Subword 26: '##ಿ' -> maps to word 8\n  Subword 27: '##ಳಿದ' -> maps to word 8\n  Subword 28: '##ಿದೆ' -> maps to word 8\n  Subword 29: '.' -> maps to word 8\n==================================================\nALIGNMENT RESULTS:\n==================================================\nSUBWORD ALIGNMENTS:\nSubword 1 'universe' (from word 1 'universe') <-> Subword 2 '##ಶ್' (from word 0 'ವಿಶ್ವವು')\nSubword 1 'universe' (from word 1 'universe') <-> Subword 3 '##ವ' (from word 0 'ವಿಶ್ವವು')\nSubword 2 'is' (from word 2 'is') <-> Subword 9 '##ವಾಗಿದೆ' (from word 1 'ವಿಶಾಲವಾಗಿದೆ')\nSubword 3 'vast' (from word 3 'vast') <-> Subword 5 'ವ' (from word 1 'ವಿಶಾಲವಾಗಿದೆ')\nSubword 4 'and' (from word 4 'and') <-> Subword 10 'ಮತ್ತು' (from word 2 'ಮತ್ತು')\nSubword 6 'knows' (from word 6 'knows') <-> Subword 27 '##ಳಿದ' (from word 8 'ತಿಳಿದಿದೆ.')\nSubword 8 'many' (from word 8 'many') <-> Subword 16 '##ಷ್ಟು' (from word 4 'ಎಷ್ಟು')\nSubword 9 'species' (from word 9 'species') <-> Subword 17 'ಜ' (from word 5 'ಜಾತಿಗಳಿವೆ')\nSubword 10 'are' (from word 10 'are') <-> Subword 21 '##ಿವೆ' (from word 5 'ಜಾತಿಗಳಿವೆ')\nSubword 11 'within' (from word 11 'within') <-> Subword 14 '##ಗೆ' (from word 3 'ಅದರೊಳಗೆ')\nSubword 12 'it' (from word 12 'it.') <-> Subword 11 'ಅದರ' (from word 3 'ಅದರೊಳಗೆ')\nSubword 13 '.' (from word 12 'it.') <-> Subword 29 '.' (from word 8 'ತಿಳಿದಿದೆ.')\n\nWORD-LEVEL ALIGNMENTS:\nWord 1 'universe' <-> Word 0 'ವಿಶ್ವವು'\nWord 2 'is' <-> Word 1 'ವಿಶಾಲವಾಗಿದೆ'\nWord 3 'vast' <-> Word 1 'ವಿಶಾಲವಾಗಿದೆ'\nWord 4 'and' <-> Word 2 'ಮತ್ತು'\nWord 6 'knows' <-> Word 8 'ತಿಳಿದಿದೆ.'\nWord 8 'many' <-> Word 4 'ಎಷ್ಟು'\nWord 9 'species' <-> Word 5 'ಜಾತಿಗಳಿವೆ'\nWord 10 'are' <-> Word 5 'ಜಾತಿಗಳಿವೆ'\nWord 11 'within' <-> Word 3 'ಅದರೊಳಗೆ'\nWord 12 'it.' <-> Word 3 'ಅದರೊಳಗೆ'\nWord 12 'it.' <-> Word 8 'ತಿಳಿದಿದೆ.'\n\nFinal alignment set: {(10, 5), (8, 4), (2, 1), (3, 1), (6, 8), (11, 3), (4, 2), (12, 3), (9, 5), (1, 0), (12, 8)}\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from transformers import AutoModel, AutoTokenizer, PreTrainedTokenizerFast\nimport itertools\nimport torch\nfrom collections import defaultdict, Counter\n\nalign_model = AutoModel.from_pretrained(\"aneuraz/awesome-align-with-co\")\nalign_tokenizer = AutoTokenizer.from_pretrained(\"aneuraz/awesome-align-with-co\")\n\nkn_tokenizer = PreTrainedTokenizerFast.from_pretrained(\"charanhu/kannada-tokenizer\")\n\nalign_layer = 8\nthreshold = 1e-3\n\nall_token_pairs = []  \npair_frequency = Counter() \n\ndef get_alignments(src_text, tgt_text):\n    \"\"\"\n    Get word alignments using awesome-align model\n    Returns: set of (src_word_idx, tgt_word_idx) tuples\n    \"\"\"\n    sent_src = src_text.strip().split()\n    sent_tgt = tgt_text.strip().split()\n\n    # awesome aligner for mapping src to tgt word \n    token_src = [align_tokenizer.tokenize(word) for word in sent_src]\n    token_tgt = [align_tokenizer.tokenize(word) for word in sent_tgt]\n    \n    # tokens to IDs\n    wid_src = [align_tokenizer.convert_tokens_to_ids(x) for x in token_src]\n    wid_tgt = [align_tokenizer.convert_tokens_to_ids(x) for x in token_tgt]\n    \n    ids_src = align_tokenizer.prepare_for_model(\n        list(itertools.chain(*wid_src)), \n        return_tensors='pt', \n        model_max_length=align_tokenizer.model_max_length, \n        truncation=True\n    )['input_ids']\n    \n    ids_tgt = align_tokenizer.prepare_for_model(\n        list(itertools.chain(*wid_tgt)), \n        return_tensors='pt', \n        truncation=True, \n        model_max_length=align_tokenizer.model_max_length\n    )['input_ids']\n    \n    # Create subword to word mapping\n    sub2word_map_src = []\n    for i, word_list in enumerate(token_src):\n        sub2word_map_src += [i for x in word_list]\n    \n    sub2word_map_tgt = []\n    for i, word_list in enumerate(token_tgt):\n        sub2word_map_tgt += [i for x in word_list]\n    \n    # Get alignments\n    align_model.eval()\n    with torch.no_grad():\n        out_src = align_model(ids_src.unsqueeze(0), output_hidden_states=True)[2][align_layer][0, 1:-1]\n        out_tgt = align_model(ids_tgt.unsqueeze(0), output_hidden_states=True)[2][align_layer][0, 1:-1]\n        \n        dot_prod = torch.matmul(out_src, out_tgt.transpose(-1, -2))\n        softmax_srctgt = torch.nn.Softmax(dim=-1)(dot_prod)\n        softmax_tgtsrc = torch.nn.Softmax(dim=-2)(dot_prod)\n        softmax_inter = (softmax_srctgt > threshold) * (softmax_tgtsrc > threshold)\n    \n    align_subwords = torch.nonzero(softmax_inter, as_tuple=False)\n    \n    # word level  alignments \n    align_words = set()\n    for i, j in align_subwords:\n        align_words.add((sub2word_map_src[i], sub2word_map_tgt[j]))\n    \n    return align_words, sent_src, sent_tgt\n\nfor idx, (src_text, tgt_text) in enumerate(zip(train_data[\"src\"], train_data[\"tgt\"])):\n    if idx % 100 == 0: \n        print(f\"Processed {idx} sentences...\")\n    \n    try:\n        alignments, src_words, tgt_words = get_alignments(src_text, tgt_text)\n        \n        en_tokens = align_tokenizer.tokenize(src_text)  \n        \n        kn_tokens = align_tokenizer.tokenize(tgt_text)    \n        \n        # create token pairs from alignments\n        for src_idx, tgt_idx in alignments:\n            if src_idx < len(en_tokens) and tgt_idx < len(kn_tokens):\n                en_token = en_tokens[src_idx]\n                kn_token = kn_tokens[tgt_idx] if tgt_idx < len(kn_tokens) else tgt_words[tgt_idx]\n                \n                # create token pair\n                token_pair = (en_token, kn_token)\n                all_token_pairs.append(token_pair)\n                \n                # ct frequency\n                pair_frequency[token_pair] += 1\n        \n        if idx < 3:\n            print(f\"\\nExample {idx + 1}:\")\n            print(f\"English: {src_text}\")\n            print(f\"Kannada: {tgt_text}\")\n            print(f\"Alignments: {alignments}\")\n            print(f\"Token pairs: {[(en_tokens[i], kn_tokens[j] if j < len(kn_tokens) else tgt_words[j]) for i, j in alignments if i < len(en_tokens)]}\")\n            \n    except Exception as e:\n        print(f\"Error processing sentence {idx}: {e}\")\n        continue\n\nprint(f\"\\nAlignment processing complete!\")\nprint(f\"Total unique token pairs: {len(pair_frequency)}\")\nprint(f\"Total alignment instances: {sum(pair_frequency.values())}\")\n\n# Display most frequent token pairs\nprint(\"\\nMost frequent token pairs:\")\nfor (en_token, kn_token), freq in pair_frequency.most_common(20):\n    print(f\"'{en_token}' <-> '{kn_token}': {freq} times\")\n\n# Filter by minimum frequency threshold\nmin_frequency = 5\nfiltered_pairs = {pair: freq for pair, freq in pair_frequency.items() if freq >= min_frequency}\nprint(f\"\\nToken pairs with frequency >= {min_frequency}: {len(filtered_pairs)}\")\n\ntorch.save(pair_frequency, 'kannada_english_token_pairs.pt')\nprint(\"tok pair saved\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-03T14:00:29.138670Z","iopub.execute_input":"2025-07-03T14:00:29.138923Z","iopub.status.idle":"2025-07-03T14:01:11.173579Z","shell.execute_reply.started":"2025-07-03T14:00:29.138895Z","shell.execute_reply":"2025-07-03T14:01:11.172569Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1899cf7a628948118676f5c2356c6dc9"}},"metadata":{}},{"name":"stderr","text":"2025-07-03 14:00:47.202271: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1751551247.394399      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1751551247.452753      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.09G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1d21c87525647219648a5a7e79ad27d"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertModel were not initialized from the model checkpoint at aneuraz/awesome-align-with-co and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.09G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa480443af2a4e2192b105b13b2b1935"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/40.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e07a12c195c240cbbade61bb11ecb0f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c90439d2494e47928aa9460950e1cd84"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c57697847d4430d860d5b408becbaf5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6771236ce7b477e9f19df9ed9e46959"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b05880fb755a48e98ca80f837897bd51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2dcaaaf16b8e40ddb1a919983fa506db"}},"metadata":{}},{"name":"stdout","text":"Processing sentence pairs...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/3488356445.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;31m# Process each sentence pair\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Processing sentence pairs...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msrc_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_text\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"src\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tgt\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Processed {idx} sentences...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"],"ename":"NameError","evalue":"name 'train_data' is not defined","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"from transformers import AutoModel, AutoTokenizer\nfrom datasets import load_dataset\nimport itertools\nimport torch\nimport json\nimport pickle\nfrom tqdm import tqdm\nimport os\nfrom typing import List, Tuple, Set, Dict, Any\nimport gc\n\nclass WordAligner:\n    def __init__(self, model_name=\"aneuraz/awesome-align-with-co\", align_layer=8, threshold=1e-3, use_gpu=True):\n        \"\"\"Initialize the word aligner with model and parameters.\"\"\"\n        print(\"Loading model and tokenizer...\")\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() and use_gpu else \"cpu\")\n        print(f\"Using device: {self.device}\")\n        \n        self.model = AutoModel.from_pretrained(model_name, torch_dtype=torch.float16).to(self.device)\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n        self.align_layer = align_layer\n        self.threshold = threshold\n        self.model.eval()\n        \n        \n        self.use_amp = use_gpu and torch.cuda.is_available()\n        if self.use_amp:\n            print(\"mixed precision for faster inference\")\n        \n        print(\"model loaded\")\n    \n    def align_sentence_pair(self, src_text: str, tgt_text: str) -> Dict[str, Any]:\n        \"\"\"\n            src_words: list of source words\n            tgt_words: list of target words\n            word_alignments: set of (src_idx, tgt_idx) tuples\n            subword_alignments: list of detailed subword alignment info\n        \"\"\"\n            sent_src = src_text.strip().split()\n            sent_tgt = tgt_text.strip().split()\n            \n            if not sent_src or not sent_tgt:\n                return None\n            \n            token_src = [self.tokenizer.tokenize(word) for word in sent_src]\n            token_tgt = [self.tokenizer.tokenize(word) for word in sent_tgt]\n            \n            if not all(token_src) or not all(token_tgt):\n                return None\n            \n            # flatten token lists \n            flat_tokens_src = list(itertools.chain(*token_src))\n            flat_tokens_tgt = list(itertools.chain(*token_tgt))\n            \n            wid_src = [self.tokenizer.convert_tokens_to_ids(x) for x in token_src]\n            wid_tgt = [self.tokenizer.convert_tokens_to_ids(x) for x in token_tgt]\n            \n            ids_src = self.tokenizer.prepare_for_model(\n                list(itertools.chain(*wid_src)), \n                return_tensors='pt', \n                model_max_length=self.tokenizer.model_max_length, \n                truncation=True\n            )['input_ids'].to(self.device)\n            \n            ids_tgt = self.tokenizer.prepare_for_model(\n                list(itertools.chain(*wid_tgt)), \n                return_tensors='pt', \n                truncation=True, \n                model_max_length=self.tokenizer.model_max_length\n            )['input_ids'].to(self.device)\n            \n            # subword to word mappiing \n            sub2word_map_src = []\n            for word_idx, word_tokens in enumerate(token_src):\n                sub2word_map_src.extend([word_idx] * len(word_tokens))\n            \n            sub2word_map_tgt = []\n            for word_idx, word_tokens in enumerate(token_tgt):\n                sub2word_map_tgt.extend([word_idx] * len(word_tokens))\n            \n            # mixed precision \n            with torch.no_grad():\n                if self.use_amp:\n                    with torch.cuda.amp.autocast():\n                        out_src = self.model(ids_src.unsqueeze(0), output_hidden_states=True)[2][self.align_layer][0, 1:-1]\n                        out_tgt = self.model(ids_tgt.unsqueeze(0), output_hidden_states=True)[2][self.align_layer][0, 1:-1]\n                        dot_prod = torch.matmul(out_src, out_tgt.transpose(-1, -2))\n                else:\n                    out_src = self.model(ids_src.unsqueeze(0), output_hidden_states=True)[2][self.align_layer][0, 1:-1]\n                    out_tgt = self.model(ids_tgt.unsqueeze(0), output_hidden_states=True)[2][self.align_layer][0, 1:-1]\n                    dot_prod = torch.matmul(out_src, out_tgt.transpose(-1, -2))\n                \n                softmax_srctgt = torch.nn.Softmax(dim=-1)(dot_prod)\n                softmax_tgtsrc = torch.nn.Softmax(dim=-2)(dot_prod)\n                softmax_inter = (softmax_srctgt > self.threshold) * (softmax_tgtsrc > self.threshold)\n            \n            align_subwords = torch.nonzero(softmax_inter, as_tuple=False)\n            align_words = set()\n            subword_alignments = []\n            \n            for i, j in align_subwords:\n                i_idx, j_idx = i.item(), j.item()\n                \n                if i_idx >= len(sub2word_map_src) or j_idx >= len(sub2word_map_tgt):\n                    continue\n                \n                src_subword = flat_tokens_src[i_idx]\n                tgt_subword = flat_tokens_tgt[j_idx]\n                src_word_idx = sub2word_map_src[i_idx]\n                tgt_word_idx = sub2word_map_tgt[j_idx]\n                \n                subword_alignments.append({\n                    'src_subword_idx': i_idx,\n                    'tgt_subword_idx': j_idx,\n                    'src_subword': src_subword,\n                    'tgt_subword': tgt_subword,\n                    'src_word_idx': src_word_idx,\n                    'tgt_word_idx': tgt_word_idx,\n                    'src_word': sent_src[src_word_idx],\n                    'tgt_word': sent_tgt[tgt_word_idx]\n                })\n                \n                align_words.add((src_word_idx, tgt_word_idx))\n            \n            return {\n                'src_text': src_text,\n                'tgt_text': tgt_text,\n                'src_words': sent_src,\n                'tgt_words': sent_tgt,\n                'word_alignments': list(align_words),\n                'subword_alignments': subword_alignments,\n                'alignment_count': len(align_words)\n            }\n            \n\ndef process_dataset_batch(dataset, aligner, output_dir=\"alignment_output\", batch_size=4000, max_samples=None):\n    \"\"\"Process the entire dataset in batches and save alignments.\"\"\"\n    \n    # Create output directory\n    os.makedirs(output_dir, exist_ok=True)\n    \n    # Determine total samples to process\n    total_samples = len(dataset) if max_samples is None else min(max_samples, len(dataset))\n    print(f\"Processing {total_samples} sentence pairs...\")\n    \n    # Process in batches\n    batch_num = 0\n    alignments = []\n    successful_alignments = 0\n    failed_alignments = 0\n    \n    for i in tqdm(range(0, total_samples, batch_size), desc=\"Processing batches\"):\n        batch_alignments = []\n        \n        # Process current batch\n        end_idx = min(i + batch_size, total_samples)\n        for j in range(i, end_idx):\n            sample = dataset[j]\n            src_text = sample['src']  # English\n            tgt_text = sample['tgt']  # Kannada\n            \n            alignment_result = aligner.align_sentence_pair(src_text, tgt_text)\n            \n            if alignment_result is not None:\n                alignment_result['sample_idx'] = j\n                batch_alignments.append(alignment_result)\n                successful_alignments += 1\n            else:\n                failed_alignments += 1\n        \n        # Save batch to disk\n        if batch_alignments:\n            batch_file = os.path.join(output_dir, f\"alignments_batch_{batch_num:04d}.pkl\")\n            with open(batch_file, 'wb') as f:\n                pickle.dump(batch_alignments, f)\n            \n            # Also save as JSON for human readability (smaller sample)\n            if len(batch_alignments) > 0:\n                json_sample = batch_alignments[:10]  # Save first 10 as JSON for inspection\n                json_file = os.path.join(output_dir, f\"alignments_batch_{batch_num:04d}_sample.json\")\n                with open(json_file, 'w', encoding='utf-8') as f:\n                    json.dump(json_sample, f, ensure_ascii=False, indent=2)\n        \n        alignments.extend(batch_alignments)\n        batch_num += 1\n        \n        # Clear memory periodically\n        if batch_num % 10 == 0:\n            gc.collect()\n            print(f\"Processed {batch_num} batches. Success: {successful_alignments}, Failed: {failed_alignments}\")\n    \n    # Save final statistics\n    stats = {\n        'total_processed': total_samples,\n        'successful_alignments': successful_alignments,\n        'failed_alignments': failed_alignments,\n        'success_rate': successful_alignments / total_samples * 100,\n        'total_batches': batch_num\n    }\n    \n    stats_file = os.path.join(output_dir, \"alignment_stats.json\")\n    with open(stats_file, 'w') as f:\n        json.dump(stats, f, indent=2)\n    \n    print(f\"\\nAlignment completed!\")\n    print(f\"Successful alignments: {successful_alignments}\")\n    print(f\"Failed alignments: {failed_alignments}\")\n    print(f\"Success rate: {stats['success_rate']:.2f}%\")\n    print(f\"Results saved in: {output_dir}\")\n    \n    return alignments, stats\n\ndef load_alignments_from_batches(output_dir=\"alignment_output\"):\n    \"\"\"Load all alignment batches from disk.\"\"\"\n    alignments = []\n    batch_files = sorted([f for f in os.listdir(output_dir) if f.startswith(\"alignments_batch_\") and f.endswith(\".pkl\")])\n    \n    print(f\"Loading {len(batch_files)} batch files...\")\n    for batch_file in tqdm(batch_files):\n        with open(os.path.join(output_dir, batch_file), 'rb') as f:\n            batch_alignments = pickle.load(f)\n            alignments.extend(batch_alignments)\n    \n    return alignments\n\ndef create_translation_training_data(alignments, output_file=\"translation_training_data.json\"):\n    \"\"\"Create training data optimized for translation models.\"\"\"\n    training_data = []\n    \n    for alignment in alignments:\n        # Basic sentence pair\n        training_sample = {\n            'src': alignment['src_text'],\n            'tgt': alignment['tgt_text'],\n            'word_alignments': alignment['word_alignments'],\n            'alignment_count': alignment['alignment_count']\n        }\n        \n        # Add aligned word pairs for additional supervision\n        aligned_pairs = []\n        for src_idx, tgt_idx in alignment['word_alignments']:\n            aligned_pairs.append({\n                'src_word': alignment['src_words'][src_idx],\n                'tgt_word': alignment['tgt_words'][tgt_idx],\n                'src_idx': src_idx,\n                'tgt_idx': tgt_idx\n            })\n        \n        training_sample['aligned_word_pairs'] = aligned_pairs\n        training_data.append(training_sample)\n    \n    # Save training data\n    with open(output_file, 'w', encoding='utf-8') as f:\n        json.dump(training_data, f, ensure_ascii=False, indent=2)\n    \n    print(f\"Training data saved to: {output_file}\")\n    return training_data\n\n# Main execution\nif __name__ == \"__main__\":\n    # Load dataset\n    print(\"Loading Samanantar Kannada dataset...\")\n    ds = load_dataset(\"ai4bharat/samanantar\", \"kn\")\n    train_data = ds['train']\n    print(f\"Dataset loaded with {len(train_data)} samples\")\n    \n    # Initialize aligner\n    aligner = WordAligner()\n\n    # temp testing purposes \n    max_samples = 400000 \n    \n    alignments, stats = process_dataset_batch(\n        train_data, \n        aligner, \n        output_dir=\"/kaggle/working/samanantar_alignments\",\n        batch_size=2000,  # Increased batch size for GPU\n        max_samples=max_samples\n    )\n    \n    # Create translation training data\n    training_data = create_translation_training_data(\n        alignments, \n        \"/kaggle/working/samanantar_kn_translation_training.json\"\n    )\n    \n    print(f\"\\nProcessing complete! Generated {len(training_data)} training samples.\")\n    \n    # Example of how to use the alignments\n    if alignments:\n        print(\"\\nExample alignment:\")\n        example = alignments[0]\n        print(f\"Source: {example['src_text']}\")\n        print(f\"Target: {example['tgt_text']}\")\n        print(f\"Word alignments: {example['word_alignments']}\")\n        print(\"Aligned word pairs:\")\n        for src_idx, tgt_idx in example['word_alignments']:\n            print(f\"  '{example['src_words'][src_idx]}' <-> '{example['tgt_words'][tgt_idx]}'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T08:48:41.104654Z","iopub.execute_input":"2025-07-04T08:48:41.105469Z","iopub.status.idle":"2025-07-04T11:13:49.623822Z","shell.execute_reply.started":"2025-07-04T08:48:41.105437Z","shell.execute_reply":"2025-07-04T11:13:49.622957Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nCollecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.18)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\nDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: fsspec\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed fsspec-2025.3.0\nLoading Samanantar Kannada dataset...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a4050c42b6a4b7abef5121d908faf70"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00002.parquet:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca7fb30381ec48e9aff9c77e34104f43"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00001-of-00002.parquet:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc6d6dcb51014f5a851d360b03f4da53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/4093524 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"781246b2716345c8804b14026af07176"}},"metadata":{}},{"name":"stdout","text":"Dataset loaded with 4093524 samples\nLoading model and tokenizer...\nUsing device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f1fd75143c94e51bdf44930fdc61fdc"}},"metadata":{}},{"name":"stderr","text":"2025-07-04 08:50:37.015669: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1751619037.225846      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1751619037.289241      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.09G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"501fe9c1cd4a4150b7a38144641f4a9b"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertModel were not initialized from the model checkpoint at aneuraz/awesome-align-with-co and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.09G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5b046ebd4ef44ff852feee4dfa4a514"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/40.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1603858b9f164ba488fe7418110d3db7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de07936378c545fd8d497c8df468b907"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bd1057cbd664ed992ff2540194ec1e9"}},"metadata":{}},{"name":"stdout","text":"Using mixed precision for faster inference\nModel loaded successfully!\nProcessing 400000 sentence pairs...\n","output_type":"stream"},{"name":"stderr","text":"\nProcessing batches:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[AYou're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/tmp/ipykernel_35/1844822855.py:93: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n\nProcessing batches:   0%|          | 1/200 [00:46<2:32:57, 46.12s/it]\u001b[A\nProcessing batches:   1%|          | 2/200 [01:28<2:25:18, 44.03s/it]\u001b[A\nProcessing batches:   2%|▏         | 3/200 [02:11<2:22:15, 43.33s/it]\u001b[A\nProcessing batches:   2%|▏         | 4/200 [02:53<2:20:51, 43.12s/it]\u001b[A\nProcessing batches:   2%|▎         | 5/200 [03:36<2:19:55, 43.05s/it]\u001b[A\nProcessing batches:   3%|▎         | 6/200 [04:19<2:19:10, 43.05s/it]\u001b[A\nProcessing batches:   4%|▎         | 7/200 [05:02<2:18:05, 42.93s/it]\u001b[A\nProcessing batches:   4%|▍         | 8/200 [05:45<2:17:04, 42.84s/it]\u001b[A\nProcessing batches:   4%|▍         | 9/200 [06:27<2:16:09, 42.77s/it]\u001b[A\nProcessing batches:   5%|▌         | 10/200 [07:11<2:16:09, 43.00s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"Processed 10 batches. Success: 19940, Failed: 60\n","output_type":"stream"},{"name":"stderr","text":"\nProcessing batches:   6%|▌         | 11/200 [07:53<2:15:00, 42.86s/it]\u001b[A\nProcessing batches:   6%|▌         | 12/200 [08:36<2:14:02, 42.78s/it]\u001b[A\nProcessing batches:   6%|▋         | 13/200 [09:19<2:13:06, 42.71s/it]\u001b[A\nProcessing batches:   7%|▋         | 14/200 [10:01<2:12:03, 42.60s/it]\u001b[A\nProcessing batches:   8%|▊         | 15/200 [10:43<2:11:12, 42.56s/it]\u001b[A\nProcessing batches:   8%|▊         | 16/200 [11:26<2:10:20, 42.50s/it]\u001b[A\nProcessing batches:   8%|▊         | 17/200 [12:09<2:09:50, 42.57s/it]\u001b[A\nProcessing batches:   9%|▉         | 18/200 [12:51<2:09:19, 42.63s/it]\u001b[A\nProcessing batches:  10%|▉         | 19/200 [13:34<2:08:48, 42.70s/it]\u001b[A\nProcessing batches:  10%|█         | 20/200 [14:18<2:08:48, 42.93s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"Processed 20 batches. Success: 39873, Failed: 127\n","output_type":"stream"},{"name":"stderr","text":"\nProcessing batches:  10%|█         | 21/200 [15:01<2:08:11, 42.97s/it]\u001b[A\nProcessing batches:  11%|█         | 22/200 [15:43<2:07:09, 42.86s/it]\u001b[A\nProcessing batches:  12%|█▏        | 23/200 [16:26<2:06:20, 42.83s/it]\u001b[A\nProcessing batches:  12%|█▏        | 24/200 [17:09<2:05:35, 42.81s/it]\u001b[A\nProcessing batches:  12%|█▎        | 25/200 [17:52<2:05:22, 42.99s/it]\u001b[A\nProcessing batches:  13%|█▎        | 26/200 [18:35<2:04:28, 42.92s/it]\u001b[A\nProcessing batches:  14%|█▎        | 27/200 [19:17<2:03:19, 42.77s/it]\u001b[A\nProcessing batches:  14%|█▍        | 28/200 [20:00<2:02:21, 42.68s/it]\u001b[A\nProcessing batches:  14%|█▍        | 29/200 [20:43<2:02:08, 42.86s/it]\u001b[A\nProcessing batches:  15%|█▌        | 30/200 [21:27<2:02:33, 43.25s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"Processed 30 batches. Success: 59801, Failed: 199\n","output_type":"stream"},{"name":"stderr","text":"\nProcessing batches:  16%|█▌        | 31/200 [22:10<2:01:23, 43.10s/it]\u001b[A\nProcessing batches:  16%|█▌        | 32/200 [22:53<2:00:16, 42.96s/it]\u001b[A\nProcessing batches:  16%|█▋        | 33/200 [23:36<1:59:31, 42.94s/it]\u001b[A\nProcessing batches:  17%|█▋        | 34/200 [24:18<1:58:43, 42.91s/it]\u001b[A\nProcessing batches:  18%|█▊        | 35/200 [25:01<1:57:41, 42.80s/it]\u001b[A\nProcessing batches:  18%|█▊        | 36/200 [25:44<1:56:46, 42.72s/it]\u001b[A\nProcessing batches:  18%|█▊        | 37/200 [26:26<1:55:51, 42.65s/it]\u001b[A\nProcessing batches:  19%|█▉        | 38/200 [27:08<1:54:56, 42.57s/it]\u001b[A\nProcessing batches:  20%|█▉        | 39/200 [27:51<1:54:09, 42.54s/it]\u001b[A\nProcessing batches:  20%|██        | 40/200 [28:34<1:54:02, 42.77s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"Processed 40 batches. Success: 79730, Failed: 270\n","output_type":"stream"},{"name":"stderr","text":"\nProcessing batches:  20%|██        | 41/200 [29:17<1:53:08, 42.69s/it]\u001b[A\nProcessing batches:  21%|██        | 42/200 [29:59<1:52:12, 42.61s/it]\u001b[A\nProcessing batches:  22%|██▏       | 43/200 [30:41<1:51:09, 42.48s/it]\u001b[A\nProcessing batches:  22%|██▏       | 44/200 [31:24<1:50:23, 42.46s/it]\u001b[A\nProcessing batches:  22%|██▎       | 45/200 [32:06<1:49:40, 42.45s/it]\u001b[A\nProcessing batches:  23%|██▎       | 46/200 [32:48<1:48:50, 42.41s/it]\u001b[A\nProcessing batches:  24%|██▎       | 47/200 [33:31<1:47:59, 42.35s/it]\u001b[A\nProcessing batches:  24%|██▍       | 48/200 [34:13<1:47:05, 42.27s/it]\u001b[A\nProcessing batches:  24%|██▍       | 49/200 [34:55<1:46:25, 42.29s/it]\u001b[A\nProcessing batches:  25%|██▌       | 50/200 [35:38<1:46:04, 42.43s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"Processed 50 batches. Success: 99659, Failed: 341\n","output_type":"stream"},{"name":"stderr","text":"\nProcessing batches:  26%|██▌       | 51/200 [36:20<1:45:00, 42.29s/it]\u001b[A\nProcessing batches:  26%|██▌       | 52/200 [37:02<1:44:11, 42.24s/it]\u001b[A\nProcessing batches:  26%|██▋       | 53/200 [37:44<1:43:21, 42.18s/it]\u001b[A\nProcessing batches:  27%|██▋       | 54/200 [38:26<1:42:51, 42.27s/it]\u001b[A\nProcessing batches:  28%|██▊       | 55/200 [39:08<1:41:59, 42.20s/it]\u001b[A\nProcessing batches:  28%|██▊       | 56/200 [39:51<1:41:16, 42.20s/it]\u001b[A\nProcessing batches:  28%|██▊       | 57/200 [40:33<1:40:20, 42.10s/it]\u001b[A\nProcessing batches:  29%|██▉       | 58/200 [41:14<1:39:28, 42.03s/it]\u001b[A\nProcessing batches:  30%|██▉       | 59/200 [41:57<1:39:16, 42.24s/it]\u001b[A\nProcessing batches:  30%|███       | 60/200 [42:40<1:39:09, 42.50s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"Processed 60 batches. Success: 119594, Failed: 406\n","output_type":"stream"},{"name":"stderr","text":"\nProcessing batches:  30%|███       | 61/200 [43:22<1:38:07, 42.35s/it]\u001b[A\nProcessing batches:  31%|███       | 62/200 [44:04<1:37:09, 42.24s/it]\u001b[A\nProcessing batches:  32%|███▏      | 63/200 [44:47<1:36:40, 42.34s/it]\u001b[A\nProcessing batches:  32%|███▏      | 64/200 [45:29<1:35:46, 42.26s/it]\u001b[A\nProcessing batches:  32%|███▎      | 65/200 [46:11<1:34:48, 42.14s/it]\u001b[A\nProcessing batches:  33%|███▎      | 66/200 [46:53<1:34:08, 42.15s/it]\u001b[A\nProcessing batches:  34%|███▎      | 67/200 [47:35<1:33:08, 42.02s/it]\u001b[A\nProcessing batches:  34%|███▍      | 68/200 [48:16<1:32:18, 41.96s/it]\u001b[A\nProcessing batches:  34%|███▍      | 69/200 [48:58<1:31:35, 41.95s/it]\u001b[A\nProcessing batches:  35%|███▌      | 70/200 [49:42<1:31:51, 42.40s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"Processed 70 batches. Success: 139518, Failed: 482\n","output_type":"stream"},{"name":"stderr","text":"\nProcessing batches:  36%|███▌      | 71/200 [50:24<1:31:07, 42.38s/it]\u001b[A\nProcessing batches:  36%|███▌      | 72/200 [51:06<1:30:23, 42.37s/it]\u001b[A\nProcessing batches:  36%|███▋      | 73/200 [51:49<1:29:31, 42.29s/it]\u001b[A\nProcessing batches:  37%|███▋      | 74/200 [52:31<1:28:48, 42.29s/it]\u001b[A\nProcessing batches:  38%|███▊      | 75/200 [53:13<1:28:11, 42.33s/it]\u001b[A\nProcessing batches:  38%|███▊      | 76/200 [53:56<1:27:38, 42.40s/it]\u001b[A\nProcessing batches:  38%|███▊      | 77/200 [54:38<1:26:50, 42.36s/it]\u001b[A\nProcessing batches:  39%|███▉      | 78/200 [55:21<1:26:09, 42.38s/it]\u001b[A\nProcessing batches:  40%|███▉      | 79/200 [56:02<1:25:01, 42.16s/it]\u001b[A\nProcessing batches:  40%|████      | 80/200 [56:46<1:25:04, 42.53s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"Processed 80 batches. Success: 159445, Failed: 555\n","output_type":"stream"},{"name":"stderr","text":"\nProcessing batches:  40%|████      | 81/200 [57:28<1:24:08, 42.42s/it]\u001b[A\nProcessing batches:  41%|████      | 82/200 [58:10<1:23:04, 42.24s/it]\u001b[A\nProcessing batches:  42%|████▏     | 83/200 [58:51<1:22:07, 42.12s/it]\u001b[A\nProcessing batches:  42%|████▏     | 84/200 [59:33<1:21:13, 42.01s/it]\u001b[A\nProcessing batches:  42%|████▎     | 85/200 [1:00:15<1:20:23, 41.95s/it]\u001b[A\nProcessing batches:  43%|████▎     | 86/200 [1:00:57<1:19:34, 41.88s/it]\u001b[A\nProcessing batches:  44%|████▎     | 87/200 [1:01:38<1:18:47, 41.83s/it]\u001b[A\nProcessing batches:  44%|████▍     | 88/200 [1:02:20<1:18:04, 41.82s/it]\u001b[A\nProcessing batches:  44%|████▍     | 89/200 [1:03:02<1:17:13, 41.74s/it]\u001b[A\nProcessing batches:  45%|████▌     | 90/200 [1:03:45<1:17:05, 42.05s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"Processed 90 batches. Success: 179372, Failed: 628\n","output_type":"stream"},{"name":"stderr","text":"\nProcessing batches:  46%|████▌     | 91/200 [1:04:27<1:16:23, 42.05s/it]\u001b[A\nProcessing batches:  46%|████▌     | 92/200 [1:05:09<1:15:40, 42.04s/it]\u001b[A\nProcessing batches:  46%|████▋     | 93/200 [1:05:50<1:14:51, 41.98s/it]\u001b[A\nProcessing batches:  47%|████▋     | 94/200 [1:06:32<1:14:02, 41.91s/it]\u001b[A\nProcessing batches:  48%|████▊     | 95/200 [1:07:15<1:13:37, 42.08s/it]\u001b[A\nProcessing batches:  48%|████▊     | 96/200 [1:07:57<1:13:10, 42.22s/it]\u001b[A\nProcessing batches:  48%|████▊     | 97/200 [1:08:39<1:12:24, 42.18s/it]\u001b[A\nProcessing batches:  49%|████▉     | 98/200 [1:09:22<1:11:47, 42.23s/it]\u001b[A\nProcessing batches:  50%|████▉     | 99/200 [1:10:05<1:11:23, 42.41s/it]\u001b[A\nProcessing batches:  50%|█████     | 100/200 [1:10:49<1:11:33, 42.93s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"Processed 100 batches. Success: 199303, Failed: 697\n","output_type":"stream"},{"name":"stderr","text":"\nProcessing batches:  50%|█████     | 101/200 [1:11:31<1:10:47, 42.91s/it]\u001b[A\nProcessing batches:  51%|█████     | 102/200 [1:12:15<1:10:08, 42.94s/it]\u001b[A\nProcessing batches:  52%|█████▏    | 103/200 [1:12:57<1:09:25, 42.95s/it]\u001b[A\nProcessing batches:  52%|█████▏    | 104/200 [1:13:40<1:08:19, 42.70s/it]\u001b[A\nProcessing batches:  52%|█████▎    | 105/200 [1:14:22<1:07:32, 42.66s/it]\u001b[A\nProcessing batches:  53%|█████▎    | 106/200 [1:15:05<1:06:48, 42.64s/it]\u001b[A\nProcessing batches:  54%|█████▎    | 107/200 [1:15:48<1:06:18, 42.78s/it]\u001b[A\nProcessing batches:  54%|█████▍    | 108/200 [1:16:30<1:05:30, 42.73s/it]\u001b[A\nProcessing batches:  55%|█████▍    | 109/200 [1:17:13<1:04:50, 42.75s/it]\u001b[A\nProcessing batches:  55%|█████▌    | 110/200 [1:17:57<1:04:32, 43.03s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"Processed 110 batches. Success: 219235, Failed: 765\n","output_type":"stream"},{"name":"stderr","text":"\nProcessing batches:  56%|█████▌    | 111/200 [1:18:39<1:03:32, 42.84s/it]\u001b[A\nProcessing batches:  56%|█████▌    | 112/200 [1:19:22<1:02:49, 42.84s/it]\u001b[A\nProcessing batches:  56%|█████▋    | 113/200 [1:20:05<1:02:05, 42.82s/it]\u001b[A\nProcessing batches:  57%|█████▋    | 114/200 [1:20:48<1:01:31, 42.92s/it]\u001b[A\nProcessing batches:  57%|█████▊    | 115/200 [1:21:31<1:00:42, 42.85s/it]\u001b[A\nProcessing batches:  58%|█████▊    | 116/200 [1:22:14<1:00:07, 42.94s/it]\u001b[A\nProcessing batches:  58%|█████▊    | 117/200 [1:22:57<59:29, 43.01s/it]  \u001b[A\nProcessing batches:  59%|█████▉    | 118/200 [1:23:40<58:44, 42.98s/it]\u001b[A\nProcessing batches:  60%|█████▉    | 119/200 [1:24:23<57:49, 42.83s/it]\u001b[A\nProcessing batches:  60%|██████    | 120/200 [1:25:06<57:31, 43.14s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"Processed 120 batches. Success: 239172, Failed: 828\n","output_type":"stream"},{"name":"stderr","text":"\nProcessing batches:  60%|██████    | 121/200 [1:25:49<56:32, 42.94s/it]\u001b[A\nProcessing batches:  61%|██████    | 122/200 [1:26:31<55:33, 42.73s/it]\u001b[A\nProcessing batches:  62%|██████▏   | 123/200 [1:27:13<54:34, 42.52s/it]\u001b[A\nProcessing batches:  62%|██████▏   | 124/200 [1:27:55<53:44, 42.42s/it]\u001b[A\nProcessing batches:  62%|██████▎   | 125/200 [1:28:37<52:55, 42.34s/it]\u001b[A\nProcessing batches:  63%|██████▎   | 126/200 [1:29:20<52:08, 42.28s/it]\u001b[A\nProcessing batches:  64%|██████▎   | 127/200 [1:30:02<51:23, 42.25s/it]\u001b[A\nProcessing batches:  64%|██████▍   | 128/200 [1:30:44<50:41, 42.24s/it]\u001b[A\nProcessing batches:  64%|██████▍   | 129/200 [1:31:26<50:02, 42.30s/it]\u001b[A\nProcessing batches:  65%|██████▌   | 130/200 [1:32:10<49:53, 42.76s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"Processed 130 batches. Success: 259110, Failed: 890\n","output_type":"stream"},{"name":"stderr","text":"\nProcessing batches:  66%|██████▌   | 131/200 [1:32:52<48:57, 42.57s/it]\u001b[A\nProcessing batches:  66%|██████▌   | 132/200 [1:33:35<48:08, 42.47s/it]\u001b[A\nProcessing batches:  66%|██████▋   | 133/200 [1:34:17<47:25, 42.48s/it]\u001b[A\nProcessing batches:  67%|██████▋   | 134/200 [1:34:59<46:40, 42.43s/it]\u001b[A\nProcessing batches:  68%|██████▊   | 135/200 [1:35:42<45:59, 42.46s/it]\u001b[A\nProcessing batches:  68%|██████▊   | 136/200 [1:36:25<45:34, 42.73s/it]\u001b[A\nProcessing batches:  68%|██████▊   | 137/200 [1:37:08<44:54, 42.76s/it]\u001b[A\nProcessing batches:  69%|██████▉   | 138/200 [1:37:51<44:03, 42.64s/it]\u001b[A\nProcessing batches:  70%|██████▉   | 139/200 [1:38:33<43:22, 42.66s/it]\u001b[A\nProcessing batches:  70%|███████   | 140/200 [1:39:17<43:04, 43.08s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"Processed 140 batches. Success: 279044, Failed: 956\n","output_type":"stream"},{"name":"stderr","text":"\nProcessing batches:  70%|███████   | 141/200 [1:40:00<42:14, 42.97s/it]\u001b[A\nProcessing batches:  71%|███████   | 142/200 [1:40:43<41:29, 42.93s/it]\u001b[A\nProcessing batches:  72%|███████▏  | 143/200 [1:41:26<40:48, 42.95s/it]\u001b[A\nProcessing batches:  72%|███████▏  | 144/200 [1:42:09<40:06, 42.97s/it]\u001b[A\nProcessing batches:  72%|███████▎  | 145/200 [1:42:52<39:23, 42.97s/it]\u001b[A\nProcessing batches:  73%|███████▎  | 146/200 [1:43:34<38:33, 42.85s/it]\u001b[A\nProcessing batches:  74%|███████▎  | 147/200 [1:44:17<37:52, 42.89s/it]\u001b[A\nProcessing batches:  74%|███████▍  | 148/200 [1:45:01<37:15, 43.00s/it]\u001b[A\nProcessing batches:  74%|███████▍  | 149/200 [1:45:43<36:28, 42.90s/it]\u001b[A\nProcessing batches:  75%|███████▌  | 150/200 [1:46:28<36:15, 43.51s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"Processed 150 batches. Success: 298970, Failed: 1030\n","output_type":"stream"},{"name":"stderr","text":"\nProcessing batches:  76%|███████▌  | 151/200 [1:47:11<35:23, 43.33s/it]\u001b[A\nProcessing batches:  76%|███████▌  | 152/200 [1:47:54<34:33, 43.19s/it]\u001b[A\nProcessing batches:  76%|███████▋  | 153/200 [1:48:37<33:41, 43.01s/it]\u001b[A\nProcessing batches:  77%|███████▋  | 154/200 [1:49:20<32:57, 43.00s/it]\u001b[A\nProcessing batches:  78%|███████▊  | 155/200 [1:50:02<32:10, 42.90s/it]\u001b[A\nProcessing batches:  78%|███████▊  | 156/200 [1:50:45<31:24, 42.82s/it]\u001b[A\nProcessing batches:  78%|███████▊  | 157/200 [1:51:27<30:37, 42.74s/it]\u001b[A\nProcessing batches:  79%|███████▉  | 158/200 [1:52:11<29:59, 42.86s/it]\u001b[A\nProcessing batches:  80%|███████▉  | 159/200 [1:52:54<29:23, 43.01s/it]\u001b[A\nProcessing batches:  80%|████████  | 160/200 [1:53:39<29:03, 43.60s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"Processed 160 batches. Success: 318897, Failed: 1103\n","output_type":"stream"},{"name":"stderr","text":"\nProcessing batches:  80%|████████  | 161/200 [1:54:22<28:15, 43.47s/it]\u001b[A\nProcessing batches:  81%|████████  | 162/200 [1:55:05<27:29, 43.42s/it]\u001b[A\nProcessing batches:  82%|████████▏ | 163/200 [1:55:49<26:46, 43.41s/it]\u001b[A\nProcessing batches:  82%|████████▏ | 164/200 [1:56:32<26:01, 43.38s/it]\u001b[A\nProcessing batches:  82%|████████▎ | 165/200 [1:57:16<25:19, 43.41s/it]\u001b[A\nProcessing batches:  83%|████████▎ | 166/200 [1:57:59<24:32, 43.30s/it]\u001b[A\nProcessing batches:  84%|████████▎ | 167/200 [1:58:42<23:48, 43.28s/it]\u001b[A\nProcessing batches:  84%|████████▍ | 168/200 [1:59:25<23:01, 43.19s/it]\u001b[A\nProcessing batches:  84%|████████▍ | 169/200 [2:00:08<22:15, 43.09s/it]\u001b[A\nProcessing batches:  85%|████████▌ | 170/200 [2:00:53<21:49, 43.66s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"Processed 170 batches. Success: 338823, Failed: 1177\n","output_type":"stream"},{"name":"stderr","text":"\nProcessing batches:  86%|████████▌ | 171/200 [2:01:36<20:59, 43.42s/it]\u001b[A\nProcessing batches:  86%|████████▌ | 172/200 [2:02:19<20:13, 43.32s/it]\u001b[A\nProcessing batches:  86%|████████▋ | 173/200 [2:03:02<19:26, 43.19s/it]\u001b[A\nProcessing batches:  87%|████████▋ | 174/200 [2:03:44<18:39, 43.08s/it]\u001b[A\nProcessing batches:  88%|████████▊ | 175/200 [2:04:27<17:53, 42.93s/it]\u001b[A\nProcessing batches:  88%|████████▊ | 176/200 [2:05:09<17:06, 42.78s/it]\u001b[A\nProcessing batches:  88%|████████▊ | 177/200 [2:05:52<16:22, 42.73s/it]\u001b[A\nProcessing batches:  89%|████████▉ | 178/200 [2:06:35<15:40, 42.77s/it]\u001b[A\nProcessing batches:  90%|████████▉ | 179/200 [2:07:18<14:59, 42.84s/it]\u001b[A\nProcessing batches:  90%|█████████ | 180/200 [2:08:02<14:26, 43.34s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"Processed 180 batches. Success: 358755, Failed: 1245\n","output_type":"stream"},{"name":"stderr","text":"\nProcessing batches:  90%|█████████ | 181/200 [2:08:45<13:36, 43.00s/it]\u001b[A\nProcessing batches:  91%|█████████ | 182/200 [2:09:27<12:51, 42.89s/it]\u001b[A\nProcessing batches:  92%|█████████▏| 183/200 [2:10:10<12:07, 42.81s/it]\u001b[A\nProcessing batches:  92%|█████████▏| 184/200 [2:10:53<11:25, 42.86s/it]\u001b[A\nProcessing batches:  92%|█████████▎| 185/200 [2:11:35<10:41, 42.74s/it]\u001b[A\nProcessing batches:  93%|█████████▎| 186/200 [2:12:18<09:57, 42.69s/it]\u001b[A\nProcessing batches:  94%|█████████▎| 187/200 [2:13:00<09:13, 42.61s/it]\u001b[A\nProcessing batches:  94%|█████████▍| 188/200 [2:13:43<08:30, 42.56s/it]\u001b[A\nProcessing batches:  94%|█████████▍| 189/200 [2:14:25<07:47, 42.46s/it]\u001b[A\nProcessing batches:  95%|█████████▌| 190/200 [2:15:09<07:10, 43.02s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"Processed 190 batches. Success: 378678, Failed: 1322\n","output_type":"stream"},{"name":"stderr","text":"\nProcessing batches:  96%|█████████▌| 191/200 [2:15:52<06:26, 42.90s/it]\u001b[A\nProcessing batches:  96%|█████████▌| 192/200 [2:16:34<05:41, 42.73s/it]\u001b[A\nProcessing batches:  96%|█████████▋| 193/200 [2:17:17<04:58, 42.63s/it]\u001b[A\nProcessing batches:  97%|█████████▋| 194/200 [2:17:59<04:15, 42.57s/it]\u001b[A\nProcessing batches:  98%|█████████▊| 195/200 [2:18:41<03:32, 42.52s/it]\u001b[A\nProcessing batches:  98%|█████████▊| 196/200 [2:19:24<02:49, 42.45s/it]\u001b[A\nProcessing batches:  98%|█████████▊| 197/200 [2:20:06<02:07, 42.39s/it]\u001b[A\nProcessing batches:  99%|█████████▉| 198/200 [2:20:48<01:24, 42.37s/it]\u001b[A\nProcessing batches: 100%|█████████▉| 199/200 [2:21:30<00:42, 42.29s/it]\u001b[A\nProcessing batches: 100%|██████████| 200/200 [2:22:15<00:00, 42.68s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"Processed 200 batches. Success: 398614, Failed: 1386\n\nAlignment completed!\nSuccessful alignments: 398614\nFailed alignments: 1386\nSuccess rate: 99.65%\nResults saved in: /kaggle/working/samanantar_alignments\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Training data saved to: /kaggle/working/samanantar_kn_translation_training.json\n\nProcessing complete! Generated 398614 training samples.\n\nExample alignment:\nSource: Hes a scientist.\nTarget: ಇವರು ಸಂಶೋಧಕ ಸ್ವಭಾವದವರು.\nWord alignments: [(1, 2), (2, 2), (2, 1), (0, 0)]\nAligned word pairs:\n  'a' <-> 'ಸ್ವಭಾವದವರು.'\n  'scientist.' <-> 'ಸ್ವಭಾವದವರು.'\n  'scientist.' <-> 'ಸಂಶೋಧಕ'\n  'Hes' <-> 'ಇವರು'\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import json \nwith open ('/kaggle/working/samanantar_kn_translation_training.json', 'r') as file:\n    data = json.load(file)\n    print(data)\n    print(\"\\nPretty-printed JSON:\")\n    print(json.dumps(data, indent=4))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T07:43:15.175897Z","iopub.execute_input":"2025-06-30T07:43:15.176190Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install transformers torch\n!pip install -U datasets\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\n\nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model, max_seq_len=5000):\n        super().__init__()\n        pe = torch.zeros(max_seq_len, d_model)\n        position = torch.arange(0, max_seq_len).unsqueeze(1).float()\n        \n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * \n                           -(math.log(10000.0) / d_model))\n        \n        pe[:, 0::2] = torch.sin(position * div_term)\n        if d_model % 2 == 1:\n            pe[:, 1::2] = torch.cos(position * div_term[:-1])\n        else:\n            pe[:, 1::2] = torch.cos(position * div_term)\n        \n        # self.register_buffer('pe', pe.unsqueeze(0))\n    \n    def forward(self, x):\n        # input shape: [batch_size, seq_len, d_model]\n        # pe shape: [1, max_seq_len, d_model]\n        seq_len = x.size(1)\n        return x + self.pe[:, :seq_len, :]\n\n\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, d_model, n_heads):\n        super().__init__()\n        self.d_model = d_model\n        self.n_heads = n_heads\n        self.head_dim = d_model // n_heads\n        \n        self.q_linear = nn.Linear(d_model, d_model)\n        self.k_linear = nn.Linear(d_model, d_model)\n        self.v_linear = nn.Linear(d_model, d_model)\n        self.out = nn.Linear(d_model, d_model)\n        \n    def forward(self, query, key, value, mask=None):\n        batch_size = query.size(0)\n        seq_len = query.size(1)\n        \n        Q = self.q_linear(query).view(batch_size, seq_len, self.n_heads, self.head_dim).transpose(1, 2)\n        K = self.k_linear(key).view(batch_size, key.size(1), self.n_heads, self.head_dim).transpose(1, 2)\n        V = self.v_linear(value).view(batch_size, value.size(1), self.n_heads, self.head_dim).transpose(1, 2)\n        \n        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.head_dim)\n        \n        if mask is not None:\n            scores = scores.masked_fill(mask == 0, -1e9)\n            \n        attention_weights = F.softmax(scores, dim=-1)\n        context = torch.matmul(attention_weights, V)\n        \n        context = context.transpose(1, 2).contiguous().view(batch_size, seq_len, self.d_model)\n        \n        return self.out(context), attention_weights\n\nclass FeedForward(nn.Module):\n    def __init__(self, d_model, d_ff):\n        super().__init__()\n        self.linear1 = nn.Linear(d_model, d_ff)\n        self.linear2 = nn.Linear(d_ff, d_model)\n        \n    def forward(self, x):\n        return self.linear2(F.relu(self.linear1(x)))\n\nclass EncoderLayer(nn.Module):\n    def __init__(self, d_model, n_heads, d_ff, dropout=0.1):\n        super().__init__()\n        self.self_attention = MultiHeadAttention(d_model, n_heads)\n        self.feed_forward = FeedForward(d_model, d_ff)\n        self.norm1 = nn.LayerNorm(d_model)\n        self.norm2 = nn.LayerNorm(d_model)\n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, x, mask=None):\n        attn_output, _ = self.self_attention(x, x, x, mask)\n        x = self.norm1(x + self.dropout(attn_output))\n        \n        ff_output = self.feed_forward(x)\n        x = self.norm2(x + self.dropout(ff_output))\n        \n        return x\n\nclass DecoderLayer(nn.Module):\n    def __init__(self, d_model, n_heads, d_ff, dropout=0.1):\n        super().__init__()\n        self.self_attention = MultiHeadAttention(d_model, n_heads)\n        self.cross_attention = MultiHeadAttention(d_model, n_heads)\n        self.feed_forward = FeedForward(d_model, d_ff)\n        self.norm1 = nn.LayerNorm(d_model)\n        self.norm2 = nn.LayerNorm(d_model)\n        self.norm3 = nn.LayerNorm(d_model)\n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, x, encoder_output, self_mask=None, cross_mask=None):\n        self_attn_output, _ = self.self_attention(x, x, x, self_mask)\n        x = self.norm1(x + self.dropout(self_attn_output))\n        \n        cross_attn_output, cross_attention_weights = self.cross_attention(x, encoder_output, encoder_output, cross_mask)\n        x = self.norm2(x + self.dropout(cross_attn_output))\n        \n        ff_output = self.feed_forward(x)\n        x = self.norm3(x + self.dropout(ff_output))\n        \n        return x, cross_attention_weights\n\nclass TransformerEncoder(nn.Module):\n    def __init__(self, vocab_size, d_model, n_heads, n_layers, d_ff, max_seq_len, dropout=0.1):\n        super().__init__()\n        self.d_model = d_model\n        self.embedding = nn.Embedding(vocab_size, d_model)\n        self.pos_encoding = PositionalEncoding(d_model, max_seq_len)\n        self.layers = nn.ModuleList([EncoderLayer(d_model, n_heads, d_ff, dropout) for _ in range(n_layers)])\n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, src, src_mask=None):\n        x = self.embedding(src) * math.sqrt(self.d_model)\n        x = self.pos_encoding(x)\n        x = self.dropout(x)\n        \n        for layer in self.layers:\n            x = layer(x, src_mask)\n            \n        return x\n\nclass TransformerDecoder(nn.Module):\n    def __init__(self, vocab_size, d_model, n_heads, n_layers, d_ff, max_seq_len, dropout=0.1):\n        super().__init__()\n        self.d_model = d_model\n        self.embedding = nn.Embedding(vocab_size, d_model)\n        self.pos_encoding = PositionalEncoding(d_model, max_seq_len)\n        self.layers = nn.ModuleList([DecoderLayer(d_model, n_heads, d_ff, dropout) for _ in range(n_layers)])\n        self.output_projection = nn.Linear(d_model, vocab_size)\n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, tgt, encoder_output, tgt_mask=None, src_mask=None):\n        x = self.embedding(tgt) * math.sqrt(self.d_model)\n        x = self.pos_encoding(x)\n        x = self.dropout(x)\n        \n        cross_attention_weights = []\n        \n        for layer in self.layers:\n            x, cross_attn_weights = layer(x, encoder_output, tgt_mask, src_mask)\n            cross_attention_weights.append(cross_attn_weights)\n            \n        output = self.output_projection(x)\n        \n        return output, cross_attention_weights\n\nclass EnglishKannadaTransformer(nn.Module):\n    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=512, n_heads=8, \n                 n_encoder_layers=6, n_decoder_layers=6, d_ff=2048, max_seq_len=5000, dropout=0.1):\n        super().__init__()\n        \n        self.encoder = TransformerEncoder(src_vocab_size, d_model, n_heads, n_encoder_layers, \n                                        d_ff, max_seq_len, dropout)\n        self.decoder = TransformerDecoder(tgt_vocab_size, d_model, n_heads, n_decoder_layers, \n                                        d_ff, max_seq_len, dropout)\n        \n    def forward(self, src, tgt, src_mask=None, tgt_mask=None):\n        encoder_output = self.encoder(src, src_mask)\n        decoder_output, cross_attention_weights = self.decoder(tgt, encoder_output, tgt_mask, src_mask)\n        \n        return decoder_output, cross_attention_weights\n    \n    def create_masks(self, src, tgt):\n        device = src.device\n        \n        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n        \n        # causal mask + padding mask\n        tgt_len = tgt.size(1)\n        \n        tgt_mask = torch.tril(torch.ones(tgt_len, tgt_len, device=device)).unsqueeze(0).unsqueeze(0).bool()\n        \n        tgt_padding_mask = (tgt != 0).unsqueeze(1).unsqueeze(2)\n        \n        tgt_mask = tgt_mask & tgt_padding_mask\n        \n        return src_mask, tgt_mask\n        \ndef calculate_alignment_loss(cross_attention_weights, alignment_matrix, lambda_align=0.1):\n    \n    last_layer_attention = cross_attention_weights[-1]  \n    \n    avg_attention = last_layer_attention.mean(dim=1) \n    \n     # [batch, tgt_len, src_len]\n    alignment_target = alignment_matrix.transpose(-2, -1).float() \n    \n    # Calculate MSE loss\n    alignment_loss = F.mse_loss(avg_attention, alignment_target)\n    \n    return lambda_align * alignment_loss\n\ndef calculate_total_loss(model_output, target, cross_attention_weights, alignment_matrix, lambda_align=0.1):\n    # Translation loss (cross-entropy)\n    vocab_size = model_output.size(-1)\n    translation_loss = F.cross_entropy(model_output.view(-1, vocab_size), target.view(-1), ignore_index=0)\n    \n    # Alignment loss\n    alignment_loss = calculate_alignment_loss(cross_attention_weights, alignment_matrix, lambda_align)\n    \n    total_loss = translation_loss + alignment_loss\n    \n    return total_loss, translation_loss, alignment_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T06:46:54.974964Z","iopub.execute_input":"2025-07-05T06:46:54.975489Z","iopub.status.idle":"2025-07-05T06:48:29.888710Z","shell.execute_reply.started":"2025-07-05T06:46:54.975462Z","shell.execute_reply":"2025-07-05T06:48:29.888062Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nCollecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.18)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\nDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: fsspec\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed fsspec-2025.3.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport json\nfrom collections import Counter\nimport numpy as np\nfrom tqdm import tqdm\n\nclass TranslationDataset(Dataset):\n    def __init__(self, json_file_path, src_vocab=None, tgt_vocab=None, max_len=128):\n        with open(json_file_path, 'r', encoding='utf-8') as f:\n            self.data = json.load(f)\n        \n        self.max_len = max_len\n        \n        if src_vocab is None or tgt_vocab is None:\n            self.src_vocab, self.tgt_vocab = self.build_vocabularies()\n        else:\n            self.src_vocab = src_vocab\n            self.tgt_vocab = tgt_vocab\n            \n        self.src_word2idx = {word: idx for idx, word in enumerate(self.src_vocab)}\n        self.tgt_word2idx = {word: idx for idx, word in enumerate(self.tgt_vocab)}\n        \n        self.processed_data = self.process_data()\n        \n    def build_vocabularies(self):\n        src_words = []\n        tgt_words = []\n        \n        for item in self.data:\n            src_words.extend(item['src'].split())\n            tgt_words.extend(item['tgt'].split())\n            \n        src_counter = Counter(src_words)\n        tgt_counter = Counter(tgt_words)\n        \n        src_vocab = ['<pad>', '<unk>', '<sos>', '<eos>'] + [word for word, _ in src_counter.most_common()]\n        tgt_vocab = ['<pad>', '<unk>', '<sos>', '<eos>'] + [word for word, _ in tgt_counter.most_common()]\n        \n        return src_vocab, tgt_vocab\n    \n    def text_to_indices(self, text, word2idx, is_target=False):\n        words = text.split()\n        indices = []\n        \n        if is_target:\n            indices.append(word2idx.get('<sos>', 1))\n            \n        for word in words:\n            indices.append(word2idx.get(word, word2idx.get('<unk>', 1)))\n            \n        if is_target:\n            indices.append(word2idx.get('<eos>', 1))\n            \n        return indices\n    \n    def create_alignment_matrix(self, src_text, tgt_text, word_alignments):\n        src_words = src_text.split()\n        tgt_words = tgt_text.split()\n        \n        src_len = len(src_words)\n        tgt_len = len(tgt_words)\n        \n        alignment_matrix = np.zeros((src_len, tgt_len), dtype=np.float32)\n        \n        for src_idx, tgt_idx in word_alignments:\n            if src_idx < src_len and tgt_idx < tgt_len:\n                alignment_matrix[src_idx, tgt_idx] = 1.0\n                \n        return alignment_matrix\n    \n    def process_data(self):\n        processed = []\n        \n        for item in self.data:\n            src_indices = self.text_to_indices(item['src'], self.src_word2idx)\n            tgt_indices = self.text_to_indices(item['tgt'], self.tgt_word2idx, is_target=True)\n            \n            alignment_matrix = self.create_alignment_matrix(\n                item['src'], item['tgt'], item['word_alignments']\n            )\n            \n            processed.append({\n                'src': src_indices,\n                'tgt': tgt_indices,\n                'alignment': alignment_matrix\n            })\n            \n        return processed\n    \n    def __len__(self):\n        return len(self.processed_data)\n    \n    def __getitem__(self, idx):\n        return self.processed_data[idx]\n\ndef collate_fn(batch):\n    src_seqs = [item['src'] for item in batch]\n    tgt_seqs = [item['tgt'] for item in batch]\n    alignments = [item['alignment'] for item in batch]\n    \n    # Pad sequences\n    src_max_len = max(len(seq) for seq in src_seqs)\n    tgt_max_len = max(len(seq) for seq in tgt_seqs)\n    \n    src_padded = []\n    tgt_padded = []\n    tgt_input_padded = []\n    alignment_padded = []\n    \n    for i in range(len(batch)):\n        src_seq = src_seqs[i] + [0] * (src_max_len - len(src_seqs[i]))\n        tgt_seq = tgt_seqs[i] + [0] * (tgt_max_len - len(tgt_seqs[i]))\n        tgt_input_seq = tgt_seq[:-1] + [0] * (tgt_max_len - len(tgt_seq))\n        \n        # Pad alignment matrix\n        alignment = alignments[i]\n        padded_alignment = np.zeros((src_max_len, tgt_max_len - 1), dtype=np.float32)\n        padded_alignment[:alignment.shape[0], :alignment.shape[1]] = alignment\n        \n        src_padded.append(src_seq)\n        tgt_padded.append(tgt_seq[1:])  # Remove <sos> for target\n        tgt_input_padded.append(tgt_input_seq)  # Remove <eos> for input\n        alignment_padded.append(padded_alignment)\n    \n    return {\n        'src': torch.LongTensor(src_padded),\n        'tgt_input': torch.LongTensor(tgt_input_padded),\n        'tgt_output': torch.LongTensor(tgt_padded),\n        'alignment': torch.FloatTensor(np.array(alignment_padded))\n    }\n\ndef train_model(model, train_loader, val_loader, num_epochs, device, learning_rate=0.0001):\n    model.to(device)\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n    \n    best_val_loss = float('inf')\n    \n    for epoch in range(num_epochs):\n        model.train()\n        total_loss = 0\n        total_trans_loss = 0\n        total_align_loss = 0\n        \n        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n        \n        for batch_idx, batch in enumerate(progress_bar):\n            src = batch['src'].to(device)\n            tgt_input = batch['tgt_input'].to(device)\n            tgt_output = batch['tgt_output'].to(device)\n            alignment = batch['alignment'].to(device)\n            \n            optimizer.zero_grad()\n            \n            src_mask, tgt_mask = model.create_masks(src, tgt_input)\n            model_output, cross_attention_weights = model(src, tgt_input, src_mask, tgt_mask)\n            \n            total_loss_batch, trans_loss_batch, align_loss_batch = calculate_total_loss(\n                model_output, tgt_output, cross_attention_weights, alignment\n            )\n            \n            total_loss_batch.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            optimizer.step()\n            \n            # Clear cache periodically\n            if batch_idx % 100 == 0:\n                torch.cuda.empty_cache()\n            \n            total_loss += total_loss_batch.item()\n            total_trans_loss += trans_loss_batch.item()\n            total_align_loss += align_loss_batch.item()\n            \n            progress_bar.set_postfix({\n                'Loss': f'{total_loss_batch.item():.4f}',\n                'Trans': f'{trans_loss_batch.item():.4f}',\n                'Align': f'{align_loss_batch.item():.4f}'\n            })\n            \n        avg_train_loss = total_loss / len(train_loader)\n        avg_trans_loss = total_trans_loss / len(train_loader)\n        avg_align_loss = total_align_loss / len(train_loader)\n        \n        print(f'Epoch {epoch+1} - Train Loss: {avg_train_loss:.4f}, Trans: {avg_trans_loss:.4f}, Align: {avg_align_loss:.4f}')\n        \n        # Validation\n        model.eval()\n        val_loss = 0\n        with torch.no_grad():\n            for batch in val_loader:\n                src = batch['src'].to(device)\n                tgt_input = batch['tgt_input'].to(device)\n                tgt_output = batch['tgt_output'].to(device)\n                alignment = batch['alignment'].to(device)\n                \n                src_mask, tgt_mask = model.create_masks(src, tgt_input)\n                model_output, cross_attention_weights = model(src, tgt_input, src_mask, tgt_mask)\n                \n                total_loss_batch, _, _ = calculate_total_loss(\n                    model_output, tgt_output, cross_attention_weights, alignment\n                )\n                val_loss += total_loss_batch.item()\n        \n        avg_val_loss = val_loss / len(val_loader)\n        print(f'Epoch {epoch+1} - Val Loss: {avg_val_loss:.4f}')\n        \n        if avg_val_loss < best_val_loss:\n            best_val_loss = avg_val_loss\n            torch.save(model.state_dict(), '/kaggle/working/best_model.pth')\n            print(f'New best model saved with val loss: {best_val_loss:.4f}')\n        \n        scheduler.step()\n        print()\n\ndef main():\n    torch.cuda.empty_cache()\n    \n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f'Using device: {device}')\n    \n    dataset = TranslationDataset('/kaggle/input/kn-en-samanantar/samanantar_kn_translation_training (3).json')\n    \n    train_size = int(0.8 * len(dataset))\n    val_size = len(dataset) - train_size\n    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n    \n    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)\n    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n    \n    src_vocab_size = len(dataset.src_vocab)\n    tgt_vocab_size = len(dataset.tgt_vocab)\n    \n    print(f'src vocab size: {src_vocab_size}')\n    print(f'target vocab size: {tgt_vocab_size}')\n    \n    model = EnglishKannadaTransformer(\n        src_vocab_size=src_vocab_size,\n        tgt_vocab_size=tgt_vocab_size,\n        d_model=256,\n        n_heads=8,\n        n_encoder_layers=3,\n        n_decoder_layers=3,\n        d_ff=1024,\n        max_seq_len=512,\n        dropout=0.1\n    )\n    \n    print(f'model init w {sum(p.numel() for p in model.parameters())} params')\n    \n    train_model(model, train_loader, val_loader, num_epochs=5, device=device)\n    \n    torch.save(model.state_dict(), '/kaggle/working/final_model.pth')\n    \n    torch.save({\n        'src_vocab': dataset.src_vocab,\n        'tgt_vocab': dataset.tgt_vocab,\n        'src_word2idx': dataset.src_word2idx,\n        'tgt_word2idx': dataset.tgt_word2idx\n    }, '/kaggle/working/vocabularies.pth')\n    \n    print('Training completed!')\n\nif __name__ == '__main__':\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T07:19:36.853030Z","iopub.execute_input":"2025-07-05T07:19:36.853742Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nSource vocabulary size: 174304\nTarget vocabulary size: 418295\nModel initialized with 264736759 parameters\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/5:  27%|██▋       | 10735/39862 [25:25<1:10:08,  6.92it/s, Loss=9.6147, Trans=9.6126, Align=0.0021]  ","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'best_model.pth.zip')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T16:28:08.203886Z","iopub.execute_input":"2025-07-05T16:28:08.204370Z","iopub.status.idle":"2025-07-05T16:28:08.209251Z","shell.execute_reply.started":"2025-07-05T16:28:08.204347Z","shell.execute_reply":"2025-07-05T16:28:08.208573Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/best_model.pth.zip","text/html":"<a href='best_model.pth.zip' target='_blank'>best_model.pth.zip</a><br>"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'final_model.pth')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T17:15:12.819773Z","iopub.execute_input":"2025-07-05T17:15:12.820017Z","iopub.status.idle":"2025-07-05T17:15:12.825218Z","shell.execute_reply.started":"2025-07-05T17:15:12.820000Z","shell.execute_reply":"2025-07-05T17:15:12.824504Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/final_model.pth","text/html":"<a href='final_model.pth' target='_blank'>final_model.pth</a><br>"},"metadata":{}}],"execution_count":27}]}